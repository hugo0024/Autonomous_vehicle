{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflite as lite\n",
    "from tensorflow.keras.layers import Dense, Flatten,Dropout, BatchNormalization, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow_addons.metrics import RSquare\n",
    "from imgaug import augmenters as img_aug\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "import cv2\n",
    "import pickle\n",
    "import requests\n",
    "import time\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert Model:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('model/Nvidia_CNN_angle')\n",
    "tflite_model = converter.convert()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "with open('model/model_angle.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('model/Nvidia_CNN_speed')\n",
    "tflite_model = converter.convert()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "with open('model/model_speed.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def run_tflite_model(tflite_file, test_image):\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    predictions = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "converted_model = \"model/model_angle.tflite\"\n",
    "test_dir = '../datasets/PiCar/test/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On the test set:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 1.png\n",
      "Prediction: [[0.57352686]]\n",
      "Image: 2.png\n",
      "Prediction: [[0.7628894]]\n",
      "Image: 3.png\n",
      "Prediction: [[0.23380882]]\n",
      "Image: 4.png\n",
      "Prediction: [[0.11036063]]\n",
      "Image: 5.png\n",
      "Prediction: [[0.09283561]]\n",
      "Image: 6.png\n",
      "Prediction: [[0.77738875]]\n",
      "Image: 7.png\n",
      "Prediction: [[0.7020659]]\n",
      "Image: 8.png\n",
      "Prediction: [[0.7942834]]\n",
      "Image: 9.png\n",
      "Prediction: [[0.5980655]]\n",
      "Image: 10.png\n",
      "Prediction: [[0.41017088]]\n",
      "Image: 11.png\n",
      "Prediction: [[0.49714264]]\n",
      "Image: 12.png\n",
      "Prediction: [[0.74792486]]\n",
      "Image: 13.png\n",
      "Prediction: [[0.47363955]]\n",
      "Image: 14.png\n",
      "Prediction: [[0.60296106]]\n",
      "Image: 15.png\n",
      "Prediction: [[0.16636743]]\n",
      "Image: 16.png\n",
      "Prediction: [[0.6695315]]\n",
      "Image: 17.png\n",
      "Prediction: [[0.59051603]]\n",
      "Image: 18.png\n",
      "Prediction: [[0.7264946]]\n",
      "Image: 19.png\n",
      "Prediction: [[0.45831758]]\n",
      "Image: 20.png\n",
      "Prediction: [[0.13100587]]\n",
      "Image: 21.png\n",
      "Prediction: [[0.9438023]]\n",
      "Image: 22.png\n",
      "Prediction: [[0.21061586]]\n",
      "Image: 23.png\n",
      "Prediction: [[0.17868622]]\n",
      "Image: 24.png\n",
      "Prediction: [[0.7460843]]\n",
      "Image: 25.png\n",
      "Prediction: [[0.74339294]]\n",
      "Image: 26.png\n",
      "Prediction: [[0.76395524]]\n",
      "Image: 27.png\n",
      "Prediction: [[0.6833378]]\n",
      "Image: 28.png\n",
      "Prediction: [[0.6340253]]\n",
      "Image: 29.png\n",
      "Prediction: [[0.6888484]]\n",
      "Image: 30.png\n",
      "Prediction: [[0.7366956]]\n",
      "Image: 31.png\n",
      "Prediction: [[0.49066806]]\n",
      "Image: 32.png\n",
      "Prediction: [[0.75283587]]\n",
      "Image: 33.png\n",
      "Prediction: [[0.6927489]]\n",
      "Image: 34.png\n",
      "Prediction: [[0.741375]]\n",
      "Image: 35.png\n",
      "Prediction: [[0.57014334]]\n",
      "Image: 36.png\n",
      "Prediction: [[0.7049459]]\n",
      "Image: 37.png\n",
      "Prediction: [[0.5461453]]\n",
      "Image: 38.png\n",
      "Prediction: [[0.82409513]]\n",
      "Image: 39.png\n",
      "Prediction: [[0.5903675]]\n",
      "Image: 40.png\n",
      "Prediction: [[0.7501422]]\n",
      "Image: 41.png\n",
      "Prediction: [[0.8149567]]\n",
      "Image: 42.png\n",
      "Prediction: [[0.63540936]]\n",
      "Image: 43.png\n",
      "Prediction: [[0.18987156]]\n",
      "Image: 44.png\n",
      "Prediction: [[0.46996495]]\n",
      "Image: 45.png\n",
      "Prediction: [[0.05314242]]\n",
      "Image: 46.png\n",
      "Prediction: [[0.72335184]]\n",
      "Image: 47.png\n",
      "Prediction: [[0.74606913]]\n",
      "Image: 48.png\n",
      "Prediction: [[0.6706411]]\n",
      "Image: 49.png\n",
      "Prediction: [[0.71389145]]\n",
      "Image: 50.png\n",
      "Prediction: [[0.8331067]]\n",
      "Image: 51.png\n",
      "Prediction: [[0.63400126]]\n",
      "Image: 52.png\n",
      "Prediction: [[0.32418138]]\n",
      "Image: 53.png\n",
      "Prediction: [[0.7516502]]\n",
      "Image: 54.png\n",
      "Prediction: [[0.8243928]]\n",
      "Image: 55.png\n",
      "Prediction: [[0.7393183]]\n",
      "Image: 56.png\n",
      "Prediction: [[0.7086859]]\n",
      "Image: 57.png\n",
      "Prediction: [[0.5520321]]\n",
      "Image: 58.png\n",
      "Prediction: [[0.7145008]]\n",
      "Image: 59.png\n",
      "Prediction: [[0.1667623]]\n",
      "Image: 60.png\n",
      "Prediction: [[0.8097951]]\n",
      "Image: 61.png\n",
      "Prediction: [[0.7196902]]\n",
      "Image: 62.png\n",
      "Prediction: [[0.471967]]\n",
      "Image: 63.png\n",
      "Prediction: [[0.7855891]]\n",
      "Image: 64.png\n",
      "Prediction: [[0.7298683]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m resized \u001B[38;5;241m=\u001B[39m resized \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.\u001B[39m\n\u001B[0;32m     14\u001B[0m test_image \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(resized, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 15\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[43mrun_tflite_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconverted_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_image\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage:\u001B[39m\u001B[38;5;124m\"\u001B[39m, img_name)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrediction:\u001B[39m\u001B[38;5;124m\"\u001B[39m, prediction)\n",
      "Cell \u001B[1;32mIn[4], line 7\u001B[0m, in \u001B[0;36mrun_tflite_model\u001B[1;34m(tflite_file, test_image)\u001B[0m\n\u001B[0;32m      5\u001B[0m output_details \u001B[38;5;241m=\u001B[39m interpreter\u001B[38;5;241m.\u001B[39mget_output_details()\n\u001B[0;32m      6\u001B[0m interpreter\u001B[38;5;241m.\u001B[39mset_tensor(input_details[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m], test_image)\n\u001B[1;32m----> 7\u001B[0m \u001B[43minterpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m predictions \u001B[38;5;241m=\u001B[39m interpreter\u001B[38;5;241m.\u001B[39mget_tensor(output_details[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m predictions\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:917\u001B[0m, in \u001B[0;36mInterpreter.invoke\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    905\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Invoke the interpreter.\u001B[39;00m\n\u001B[0;32m    906\u001B[0m \n\u001B[0;32m    907\u001B[0m \u001B[38;5;124;03mBe sure to set the input sizes, allocate tensors and fill values before\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;124;03m  ValueError: When the underlying interpreter fails raise ValueError.\u001B[39;00m\n\u001B[0;32m    915\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_safe()\n\u001B[1;32m--> 917\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Extract numeric part of file name for sorting\n",
    "def extract_numeric_part(s):\n",
    "    return int(re.findall('\\d+', s)[0])\n",
    "\n",
    "# Get list of files in numerical order\n",
    "files = sorted(os.listdir(test_dir), key=extract_numeric_part)\n",
    "\n",
    "# Loop through all images in sorted order\n",
    "for img_name in files:\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    resized = cv2.resize(img, (224, 224)).astype('float32')\n",
    "    resized = resized / 255.\n",
    "    test_image = np.expand_dims(resized, axis=0)\n",
    "    prediction = run_tflite_model(converted_model, test_image)\n",
    "    print(\"Image:\", img_name)\n",
    "    print(\"Prediction:\", prediction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
